---
title: "`kedro_tdda` tutorial"
jupyter: python3
format: 
    html: 
        toc: true
        embed-resources: true
---

<!-- 
Note for self
demo.html is committed after a local render and project script run
```sh
quarto render ./demo.qmd
quarto run fix-shell.py
```
-->

This tutorial elaborates on the workflow and behavior of `kedro_tdda`.
It departs from the `kedro-iris` starter template which can be reproduced with

```sh
kedro new --name=kedro-iris-tdda --tools=data --example=yes
```

```{python}
#| echo: false
#| output: false
%cd ./kedro-iris-tdda
```

```{python}
#| echo: false
#| output: false
!kedro run
```

When `kedro_tdda` is installed you can use the `kedro tdda` from the command line

```{python}
!kedro tdda -h
```


### `discover`

With discover, you can write constraints to the `conf/<<env>>/tdda/` folder
for all available pandas datasets. 


```{python}
!kedro tdda discover
```

An example constraints file that is auto-generated for companies below.
For more extended use cases, check the [tdda docs](https://github.com/tdda/tdda/blob/master/tdda/constraints/tdda_json_file_format.md)
and extend the examples in `yaml` format

```{python}
!cat ./conf/base/tdda/companies.yml
```

Optional arguments for discover are

```{python}
!kedro tdda discover --help
```

### `verify`

`verify` will check constraints for data


```{python}
!kedro tdda verify --dataset companies
```


Optional arguments for discover are

```{python}
!kedro tdda verify --help
```


### `TddaHooks`

`TddaHooks` include dataset validation when a pandas dataset is loaded, for example
during a kedro pipeline run. Let's modify the constraints for `companies` and run a pipeline.
Now, a TddaVerificationError is raised.

```{python}
import yaml

filepath = './conf/base/tdda/companies.yml'
with open(filepath, 'r') as f:
    constr = yaml.safe_load(f)

# modify constraint
constr['companies']['fields']['company_location']['max_length'] = 20 # instead of 29
with open(filepath, 'w') as f:
    yaml.safe_dump(constr, f)
```

```{python}
#| error: true
!kedro run
```

### `detect`

`detect` will write csv files containing observations not matching one or more field expectations.

```{python}
!kedro tdda detect
```


Optional arguments for discover are

```{python}
!kedro tdda verify --help
```

An example, continuing our companies datasets below.

```{python}
import pandas as pd

# read raw companies and anomalies
companies = pd.read_csv('data/01_raw/companies.csv').reset_index()[['index', 'company_location']]
companies_detected = pd.read_csv('./tdda_detect/companies.csv')

companies.merge(companies_detected, how='outer', left_on='index', right_on='Index').head(15)
```


```{python}
#| echo: false
%%bash
rm -r -f conf/base/tdda/*
rm -r -f tdda_detect/*
```